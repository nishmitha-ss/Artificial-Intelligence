{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "mndata = MNIST('mnist')\n",
    "\n",
    "X_train, y_train = mndata.load_training()\n",
    "X_test, y_test = mndata.load_testing()\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "id = 7\n",
    "\n",
    "image = np.array(X_train[id], dtype='float')\n",
    "pixels = image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#print(X_train[id])\n",
    "print(y_train[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.898400 using {'batch_size': 64, 'epochs': 10} sgd\n",
      "Best: 0.910733 using {'batch_size': 128, 'epochs': 10} rmsprop\n",
      "Best: 0.903933 using {'batch_size': 256, 'epochs': 10} adam\n",
      "Best: 0.764733 using {'batch_size': 64, 'epochs': 10} adagrad\n"
     ]
    }
   ],
   "source": [
    "#Tuning the hyperparameters for optimizers\n",
    "from keras.layers import Dense \n",
    "from keras.models import Sequential \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn('DelftStack')\n",
    "warnings.warn('Do not show this message')\n",
    "\n",
    "optimizers=['sgd','rmsprop','adam','adagrad']\n",
    "for i in optimizers:\n",
    "    def create_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='sigmoid', input_shape=(784,)))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=i,  \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = KerasClassifier(build_fn=create_model,verbose=0)\n",
    "    batchsize = [64,128,256,512,1024]\n",
    "    epochs = [5,10]\n",
    "    param_grid=dict(batch_size=batchsize,epochs=epochs)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "    grid_result = grid.fit(X_train, y_train,verbose=0)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8687099993228913\n",
      "Test score:  0.34560734033584595\n",
      "Test accuracy:  0.9031999707221985\n"
     ]
    }
   ],
   "source": [
    "# Compiling model for sgd optimizer\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',   \n",
    "              metrics=['accuracy'])        \n",
    "\n",
    "hist = model.fit(X_train,y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=10, \n",
    "                    verbose=0)\n",
    "print(\"Average accuracy:\",np.mean(hist.history['accuracy']))\n",
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test score: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9205466568470001\n",
      "Test score:  0.24513554573059082\n",
      "Test accuracy:  0.927299976348877\n"
     ]
    }
   ],
   "source": [
    "# Compiling model for rmsprop optimizer\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X_train,y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10, \n",
    "                    verbose=0)\n",
    "print(\"Average accuracy:\",np.mean(hist.history['accuracy']))\n",
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test score: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.928125\n",
      "Test score:  0.2420876920223236\n",
      "Test accuracy:  0.9283999800682068\n"
     ]
    }
   ],
   "source": [
    "# Compiling model for adam optimizer\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X_train,y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=10, \n",
    "                    verbose=0)\n",
    "print(\"Average accuracy:\",np.mean(hist.history['accuracy']))\n",
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test score: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9412133276462555\n",
      "Test score:  0.22500473260879517\n",
      "Test accuracy:  0.9347000122070312\n"
     ]
    }
   ],
   "source": [
    "# Compiling model for adagrad optimizer\n",
    "model.compile(optimizer=\"adagrad\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X_train,y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=10, \n",
    "                    verbose=0)\n",
    "print(\"Average accuracy:\",np.mean(hist.history['accuracy']))\n",
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test score: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adagrad optimizer had the best accuracy compare to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training dataset into sub training and validation datasets\n",
    "x_val = X_train[:10000]   #1/6 th of training data\n",
    "partial_x_train = X_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "x_val=np.array(x_val)\n",
    "partial_x_train=np.array(partial_x_train)\n",
    "y_val=np.array(y_val)\n",
    "partial_y_train=np.array(partial_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 04m 34s]\n",
      "val_accuracy: 0.9335100054740906\n",
      "\n",
      "Best val_accuracy So Far: 0.9335100054740906\n",
      "Total elapsed time: 00h 12m 39s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#Tuning network architecture\n",
    "from keras_tuner import RandomSearch\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "def build_model(hp):                 \n",
    "    model=Sequential()\n",
    "    model.add(Flatten(input_shape=(784,))) \n",
    "    for i in range(hp.Int('layers',2,5)):         \n",
    "        model.add(Dense(units=hp.Int('units'+ str(i),min_value=32,max_value=512,step=32),\n",
    "                                    activation=hp.Choice('activ'+ str(i),['relu','sigmoid','tanh'])))\n",
    "    model.add(Dense(10,activation='softmax'))    \n",
    "    model.compile(optimizer='adagrad',   \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner=RandomSearch(build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=10)\n",
    "tuner.search_space_summary()\n",
    "tuner.search(partial_x_train,partial_y_train,batch_size=64,epochs=10,validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units0: 416\n",
      "activ0: relu\n",
      "units1: 288\n",
      "activ1: relu\n",
      "units2: 192\n",
      "activ2: tanh\n",
      "units3: 224\n",
      "activ3: relu\n",
      "units4: 224\n",
      "activ4: tanh\n",
      "Score: 0.9335100054740906\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units0: 224\n",
      "activ0: sigmoid\n",
      "units1: 128\n",
      "activ1: tanh\n",
      "units2: 32\n",
      "activ2: relu\n",
      "Score: 0.9032799959182739\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 5\n",
      "units0: 480\n",
      "activ0: sigmoid\n",
      "units1: 448\n",
      "activ1: sigmoid\n",
      "units2: 224\n",
      "activ2: tanh\n",
      "units3: 32\n",
      "activ3: relu\n",
      "units4: 32\n",
      "activ4: relu\n",
      "Score: 0.892769992351532\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training and validation accuracy: 0.9076999962329865\n",
      "Test score:  0.21896737813949585\n",
      "Test accuracy:  0.932699978351593\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(784,)))\n",
    "model.add(Dense(416, activation='relu'))\n",
    "model.add(Dense(288, activation='relu'))\n",
    "model.add(Dense(192, activation='tanh'))\n",
    "model.add(Dense(224, activation='relu'))\n",
    "model.add(Dense(224, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adagrad\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(partial_x_train,partial_y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=10, \n",
    "                 verbose=0,\n",
    "                 validation_data=(x_val,y_val))\n",
    "print(\"Average training and validation accuracy:\",np.mean(hist.history['accuracy']))\n",
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test score: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training and validation accuracy: 0.8424000084400177\n",
      "Test score:  0.3485741913318634\n",
      "Test accuracy:  0.900600016117096\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(784,)))\n",
    "model.add(Dense(224, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adagrad\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(partial_x_train,partial_y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=10, \n",
    "                 verbose=0,\n",
    "                 validation_data=(x_val,y_val))\n",
    "print(\"Average training and validation accuracy:\",np.mean(hist.history['accuracy']))\n",
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test score: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training and validation accuracy: 0.7806379973888398\n",
      "Test score:  0.37904125452041626\n",
      "Test accuracy:  0.8928999900817871\n"
     ]
    }
   ],
   "source": [
    "#Model 3\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(784,)))\n",
    "model.add(Dense(480, activation='sigmoid'))\n",
    "model.add(Dense(448, activation='sigmoid'))\n",
    "model.add(Dense(224, activation='tanh'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adagrad\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(partial_x_train,partial_y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=10, \n",
    "                 verbose=0,\n",
    "                 validation_data=(x_val,y_val))\n",
    "print(\"Average training and validation accuracy:\",np.mean(hist.history['accuracy']))\n",
    "result = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test score: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
